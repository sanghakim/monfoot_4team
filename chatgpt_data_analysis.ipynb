{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAlYVg2nJbqRK2tfhxFlNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanghakim/project_emba/blob/main/chatgpt_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsA2pKq2K5D9",
        "outputId": "18bb5997-337d-406c-c6ff-b491f4b68da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "## 주의!! 현재 API 과금 중으로 실험용 대량 사용 자제\n",
        "openai.organization = \"org-gw93z6sJDGC3Glk5glhx1Om2\"\n",
        "openai.api_key = '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'\n",
        "#os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "You will be presented with user reviews and your job is to provide a set of tags from the following list.\n",
        "Choose ONLY from the list of tags provided here (choose either the positive or the negative tag but NOT both):\n",
        "\n",
        "우리가 판매하는 제품에 대한 사용자 리뷰를 보여줄거야.\n",
        "해당 리뷰에 대해 긍정 또는 부정으로 분류해서 태그를 달아주고 간략하게 한줄로 한국어로 요약해줘.\n",
        "그리고 재구매 의사가 있을지도 추정해서 알려줘.\n",
        "\n",
        "예를 들면, 다음과 같이 대답하면 됩니다.\n",
        "\n",
        "<REVIEW>\n",
        "These socks are great! I was looking for an ankle sock with thick cushioning on the bottom and these are it! The cushioning seems thicker than most and when you are on your feet for 12 hours shifts the cushioning really does help your feet.\n",
        "\n",
        "<RESULT>\n",
        "- posivitve\n",
        "- 쿠션이 있어서 발이 편안하고 좋음\n",
        "- 재구매 의사 있음\n",
        "\n",
        "<REVIEW>\n",
        "I was reordering these low anklet socks because I like them! I received very inferior ugly high rise socks of a different brand! I am not happy about having to return these. I’m afraid to reorder even tho I really want what I ordered!\n",
        "\n",
        "<RESULT>\n",
        "- negative\n",
        "- 주문한것과 다른 제품이 와서 실망함\n",
        "- 재구매 고려 안함\n",
        "\n",
        "<REVIEW>\n",
        "\"\"\"\n",
        "\n",
        "## read review files\n",
        "review_file = '40_review_of_MONFOOT-Pairs-Cushion-Non-Slip-Socks.csv'\n",
        "data = pd.read_csv(review_file, header=0, names = ['Name', 'Stars', 'Title', 'Date', 'Description'])\n",
        "reviews = data['Description'].to_list()\n",
        "print('Total number of reviews: {0}\\n'.format(len(reviews)))\n",
        "\n",
        "'''\n",
        "reviews = [\n",
        "    \"These socks are made well and very comfortable.\",\n",
        "    \"These are really good socks! I've worn out all of my short socks that I purchased 7 years ago and have been hesitant to buy any online not knowing anything about them. I rolled the dice and orderd these socks. I wear size 12 and have a hard time finding socks that are part cotton that fit and have some stretch to them. These arrived on time and in a zip-lock type of bag and they were not stuck together with the little plastic do-dads. I have been wearing them daily, a new pair each day btw and they feel great. The jury is still out on how they will hold though.\",\n",
        "    \"They are very soft and provide good cushioning, but run a bit small if you're at the top of the size range. I wear a women's 10 and should have gone to a large as they are slipping off my heels.\",\n",
        "    \"I love these socks! However, the color is not white. It's off white... Specifically, the socks contrast with white Keds, Vans, and/or Converse shoes. You don't notice they are not white until you put them against something white. All that being said, these socks will be my 'house and sleeping socks'--they are comfy!! One person found this helpful\",\n",
        "    \"These socks don't stay up. They keep sliding down over the heel\",\n",
        "    \"First of all, I was expecting 10 pairs of socks, not 10 socks total. Second, these socks have elastic arch support, which I did not want and was not listed in the ad. Third, I purchased them using the handy size guide only to find out there is no way my foot is going to fit in the size they sent. These socks run very small. Lastly, there was rubber stuff along the heel to keep the sock from sliding down. Again, not mentioned in the ad and not wanted.\",\n",
        "    \"These socks appear to be well made. The stitching quality looks good. The material is comfortable. I've owned these socks for months now. I'd like to give this a positive rating. However, I can't. These socks slide down my feet. They will slide off in the shoe. Every time! I tend to wear my shoes loosely. Even when I tighten them, the socks still slide off. I even tested them by wearing them around my house without any shoes and they still slide off. You might say that I got the wrong size. The heel and toes are right where they are supposed to be and the socks are not tight on my feet. Whatever the issues are to cause this, it's beyond me to figure out.\"\n",
        "]\n",
        "'''\n",
        "## 실험용으로 4개의 리뷰만 확인\n",
        "for review in reviews[6:10]:\n",
        "  print('{0}\\n'.format(review))\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo-0613\",\n",
        "      messages = [ {\"role\": \"user\", \"content\": user_prompt + review}],\n",
        "      temperature=0,\n",
        "      max_tokens=1024\n",
        "  )\n",
        "  print('<RESULT>\\n{0}\\n\\n'.format(response[\"choices\"][0][\"message\"][\"content\"].replace('<RESULT>\\n', '')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eqq2MpYK401",
        "outputId": "75ab6c44-ecf1-4a9d-d76f-93d436f723e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of reviews: 270\n",
            "\n",
            "By far the best socks EVER! Have little grips on the heel that make sure they don’t slide around all day. They are super plush and I wear them everyday!\n",
            "\n",
            "<RESULT>\n",
            "- positive\n",
            "- 발뒤꿈치에 그립이 있어서 편하게 신을 수 있음\n",
            "- 재구매 의사 있음\n",
            "\n",
            "\n",
            "These are about what you pay for. Don't expect to last for a long time, but for the price I think they're worth it. Shipped promptly with no problems.\n",
            "\n",
            "<RESULT>\n",
            "- positive\n",
            "- 가격 대비 괜찮음\n",
            "- 재구매 의사 있음\n",
            "\n",
            "\n",
            "Very comfortable product would recommend for anyone\n",
            "\n",
            "<RESULT>\n",
            "- positive\n",
            "- 아무에게나 추천할만큼 편안한 제품\n",
            "- 재구매 의사 있음\n",
            "\n",
            "\n",
            "Love em\n",
            "\n",
            "<RESULT>\n",
            "- positive\n",
            "- 좋아함\n",
            "- 재구매 의사 있음\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVbBOgoqKTE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c804fa36-4676-4eed-f3ee-d9c65ba4df94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7zevTFMq0jtSijAOBQnqUyg83JJQg\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1694929683,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The current weather in Boston is sunny and windy with a temperature of 72 degrees.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 72,\n",
            "    \"completion_tokens\": 17,\n",
            "    \"total_tokens\": 89\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# multi-turn 또는 function api 사용이 필요할 경우 활용 예정\n",
        "'''\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)\n",
        "\n",
        "def run_conversation():\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
        "    functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
        "    )\n",
        "    response_message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    # Step 2: check if GPT wanted to call a function\n",
        "    if response_message.get(\"function_call\"):\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        available_functions = {\n",
        "            \"get_current_weather\": get_current_weather,\n",
        "        }  # only one function in this example, but you can have multiple\n",
        "        function_name = response_message[\"function_call\"][\"name\"]\n",
        "        fuction_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "        function_response = fuction_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "\n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=messages,\n",
        "        )  # get a new response from GPT where it can see the function response\n",
        "        return second_response\n",
        "\n",
        "print(run_conversation())\n",
        "'''"
      ]
    }
  ]
}